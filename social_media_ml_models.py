# -*- coding: utf-8 -*-
"""social_media_ml_models

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KNVgbXVS95ZahNAktOczGPEEcdWiJrBB
"""

import pandas as pd
import numpy as np
import os
from google.colab import drive
from google.colab import files
import matplotlib.pyplot as plt
drive.mount('/content/drive')
data = pd.read_csv("/content/drive/My Drive/train.csv")


#Drive already mounted at /countent/drive; to attempt to forcibly remount, call drive mount("/count/drive", force_remount=True).

"""Data Exploration"""

print(np.shape(data))
    print(data.head())

print(data.info())

data_set = data.iloc[:,1:-1]
print(data_set.iloc[:,0])
from sklearn.preprocessing import LabelEncoder
data_set.iloc[:,0] = LabelEncoder().fit_transform(data_set.iloc[:,0])
data_set['diagnosis'].value_counts()
print(data_set)

print(np.shape(data_set))
print(data_set.head())
data_set.describe()

import matplotlib.pyplot as plt
data_set.hist(bins=50, figsize=(20,15))
plt.show()

data_set.corr()

from sklearn.model_selection import train_test_split
train, test = train_test_split(data_set, test_size=0.2, random_state=42)

Y_train = train.iloc[:,0]
Y_test = test.iloc[:,0]
X_train =train.iloc[:,1:]
X_test = test.iloc[:,1:]

import numpy.matlib
X_train_N = X_train.shape[0]
X_train_mean = np.mean(X_train, axis=0)
X_train_std = np.std(X_train, axis = 0)
trn_ctr_param = X_train-np.matlib.repmat(X_train_mean, X_train_N, 1)
trn_scl_param = np.matlib.repmat(X_train_std, X_train_N, 1)
X_train= trn_ctr_param/trn_scl_param

X_test_N = X_test.shape[0]

tst_ctr_param = X_test-np.matlib.repmat(X_train_mean, X_test_N, 1)
tst_scl_param = np.matlib.repmat(X_train_std, X_test_N, 1)

X_test = tst_ctr_param/tst_scl_param

print(Y_train.head())

beta, res, rank, s_vals = np.linalg.lstsq(X_train, Y_train, rcond=None )
print(beta)
features = data_set.columns
plt.figure(figsize =(60,10))
plt.bar(features[2:], beta)
plt.xlabel('Details', size =16)
plt.ylabel('Linear Regression Coefficient', size = 16)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.tight_layout()

from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV

parameter_grid = {'C':[0.01, 0.1, 1, 10, 100,],'kernel':['linear', 'sigmoid', 'poly']}
classifier_1_name = SVC(random_state=42)
grid_search_1= GridSearchCV(classifier_1_name, parameter_grid, cv=3, verbose=3)
grid_search_1.fit(X_train, Y_train)
predictions = grid_search_1.predict(X_train)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
parameter_grid_2 = {'C':[0.01, 0.1, 1, 10, 100]}
classifier_2_name = LogisticRegression(random_state=42)
grid_search_2= GridSearchCV(classifier_2_name, parameter_grid_2, cv=3, verbose=3)
grid_search_2.fit(X_train, Y_train)
predictions2 = grid_search_2.predict(X_train)

data_set.head()

start = 1
stop = 20
color_map = {-1: '#0392cf', 1: '#7bc043'}  # 0 (negative class): blue, 1 (positive class): green
colors = data_set.iloc[:,0].map(lambda x: color_map.get(x))
pd.plotting.scatter_matrix(data_set.iloc[:,start:stop], alpha=0.5, c=colors, figsize=(12,14), diagonal='hist', hist_kwds={'bins':12})
plt.suptitle('Scatter matrix of target and model features')
plt.show()

y-preds = models.predict(X_train)
sklearn.metrics.classification_report(X_train, y-preds)